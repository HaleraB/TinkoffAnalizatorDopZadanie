{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "0# Подгружение нужных ресурсов для работы библиотеки (необязательно если уже есть)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5093575b04a43bb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "import nltk\n",
    "print('Установка модели...')\n",
    "fasttext.util.download_model('ru', if_exists='ignore')\n",
    "try: \n",
    "    nltk.download('stopwords')\n",
    "except:\n",
    "    pass\n",
    "print(\"Успешно!\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75563ca3249e5519"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1# Получение самих отзывов с площадок\n",
    "Мы использовали requests(запросы) для получения страницы сайта с отзывами, затем используя BeautifulSoup получая сами отзывы, очищая их от html-развертки\n",
    "\n",
    "def get_review_from_bankiru - функция для получения отзывов с сайта банки.ру\n",
    "def get_review_from_sravniru - функция для получения отзывов с сравни.ру\n",
    "def save_reviews - функция для сохранения отзывов в json-файл"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21b5217f851d257e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_review_from_bankiru(num=100, page=1):\n",
    "    revs = {\"good\": [], \"bad\": []}\n",
    "    reviews = 0\n",
    "    links = []\n",
    "    while True:\n",
    "        req = requests.get(\"https://www.banki.ru/services/responses/bank/tcs/\" + f\"?page={page}\")\n",
    "        soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "        for h3 in soup.find_all(\"h3\", class_=\"text-weight-medium text-size-3 ldecc766d\"):\n",
    "            a = h3.find_all(\"a\")\n",
    "            links.append(a[0]['href'])\n",
    "        for link in links:\n",
    "            if reviews >= num:\n",
    "                with open(\"reviews.json\", \"w\") as f:\n",
    "                    json.dump(revs, f)\n",
    "                return revs\n",
    "            req = requests.get(\"https://www.banki.ru\" + link)\n",
    "            soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "            for div in soup.find_all(\"div\", class_=\"lb1789875 markdown-inside markdown-inside--list-type_circle-fill\"):\n",
    "                p = div.find_all(\"p\")\n",
    "                review = \"\"\n",
    "                for r in p:\n",
    "                    review += str(r.text).replace(\"\\n\", \"\").replace(\"\\r\", \"\").replace(\"\\t\", \"\")\n",
    "                if review == \"\":\n",
    "                    review += div.text.replace(\"\\n\", \"\").replace(\"\\r\", \"\").replace(\"\\t\", \"\")\n",
    "                if review != \"\" and review != \" \" and review != \"\\n\" and review != ', ':\n",
    "                    if int(soup.find_all(\"div\", class_=\"lbb810226\")[0].find_all(\"div\")[1].text) in (1, 2, 3):\n",
    "                        revs[\"bad\"].append(review)\n",
    "                    elif int(soup.find_all(\"div\", class_=\"lbb810226\")[0].find_all(\"div\")[1].text) in (4, 5):\n",
    "                        revs[\"good\"].append(review)\n",
    "                        \n",
    "                    reviews += 1\n",
    "                    print(f\"Получено отзывов с банки.ру: {reviews}/{num}\")\n",
    "\n",
    "        page += 1\n",
    "\n",
    "def get_review_from_sravniru(num=100, page=1):\n",
    "    revs = {\"good\": [], \"bad\": []}\n",
    "    r = 0\n",
    "    while True:\n",
    "        if r >= num:\n",
    "            with open(\"reviews.json\", \"w\") as f:\n",
    "                json.dump(revs, f)\n",
    "            return revs\n",
    "        req = requests.get(f\"https://www.sravni.ru/proxy-reviews/reviews/?filterBy=withRates&fingerPrint=ea060f38d490a841e5bae143a1505423&isClient=true&locationRoute=&newIds=true&orderBy=byDate&pageIndex={page}&pageSize=10&reviewObjectId=5bb4f769245bc22a520a6353&reviewObjectType=banks&specificProductId=&withVotes=true\")\n",
    "        reviews = req.json()\n",
    "        if reviews[\"items\"] == []:\n",
    "            \n",
    "            return revs\n",
    "        for item in reviews[\"items\"]:\n",
    "            review = item[\"text\"].replace(\"\\n\", \"\").replace(\"\\r\", \"\").replace(\"\\t\", \"\")\n",
    "            if review != \"\" and review != \" \" and review != \"\\n\" and review != ', ':\n",
    "                if int(item[\"rating\"]) in (1, 2, 3):\n",
    "                    revs[\"bad\"].append(review)\n",
    "                elif int(item[\"rating\"]) in (4, 5):\n",
    "                    revs[\"good\"].append(review)\n",
    "                    \n",
    "                r += 1\n",
    "                print(f\"Получено отзывов с сравни.ру: {r}/{num}\")\n",
    "        page += 1\n",
    "def save_reviews(*args: dict):\n",
    "    revs = {\"good\": [], \"bad\": []}\n",
    "    for review in args:\n",
    "        revs[\"good\"] += review[\"good\"]\n",
    "        revs[\"bad\"] += review[\"bad\"]\n",
    "    with open(\"reviews.json\", \"w\") as f:\n",
    "        json.dump(revs, f) \n",
    "\n",
    "revs_s = get_review_from_sravniru(100, 1)\n",
    "revs_b = get_review_from_bankiru(100, 1)\n",
    "save_reviews(revs_s, revs_b)\n",
    "print('Успешно!\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf4079fa117257b7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "2# Очистка лишних данных в отзывах и приведение в нижний регистр\n",
    "В данном фрагменте кода мы делали пред-обработку отзывов используя re для удаления от лишних символов(unicode-символы, буквы латинского алфавита), а так же удаляли различные стоп-слова с помощью библиотеки обработки естественного языка(nltk)\n",
    "\n",
    "def delete_symbols - функция для удаления лишних символов в списке отзывов\n",
    "def delete_stop_words - функция для удаления стоп-слов и привод в нижний регистр предложения(текста)\n",
    "def lower_review - функция для удаления стоп-слов из списка отзывов (использует def delete_stop_words)\n",
    "def save_lower_reviews - функция для сохранения результата(списка обновленных отзывов) в json-файл"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a36ee4d24a97a4fa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def delete_symbols(reviews_a):\n",
    "    reviews_symbols = []\n",
    "    print('Очистка лишних символов в отзывах...')\n",
    "    for word in reviews_a:\n",
    "        reg_sumbols = re.sub('[^\\w\\s]+|[\\d]+', ' ', word)\n",
    "        reg_eng_symbols = re.sub('[a-zA-Z\\s]+', ' ', reg_sumbols)\n",
    "        reviews_symbols.append(reg_eng_symbols.split())\n",
    "    return reviews_symbols\n",
    "\n",
    "def delete_stop_words(review_a): \n",
    "    \n",
    "    stop_words = list(stopwords.words('russian'))\n",
    "    reviews_stop_words = []\n",
    "    for s in review_a:\n",
    "        word = s.lower()\n",
    "        if word not in stop_words and word != \"\\n\":\n",
    "            reviews_stop_words.append(word)\n",
    "    return reviews_stop_words\n",
    "\n",
    "def lower_review(reviews_a):\n",
    "    print('Удаление стоп-слов из отзывов...')\n",
    "    lower_reviews = []\n",
    "    for rev in reviews_a:\n",
    "        deleted_stop_words = delete_stop_words(rev)\n",
    "        lower_reviews.append(deleted_stop_words)\n",
    "    return lower_reviews\n",
    "\n",
    "def save_lower_reviews(reviews_a):\n",
    "    reviews_a = {\"reviews\": reviews_a}\n",
    "    print('Сохранение отзывов...')\n",
    "    with open('lower_reviews.json', 'w') as f:\n",
    "        json.dump(reviews_a, f)\n",
    "\n",
    "with open(\"reviews.json\", \"r\", encoding='utf-8') as read_file:\n",
    "    reviews_sorted = json.loads(read_file.read())\n",
    "reviews = reviews_sorted[\"good\"] + reviews_sorted[\"bad\"]\n",
    "\n",
    "reviews_deleted_symbols = delete_symbols(reviews)\n",
    "reviews_lower = lower_review(reviews_deleted_symbols)\n",
    "save_lower_reviews(reviews_lower)\n",
    "del reviews_deleted_symbols, reviews_lower, reviews_sorted\n",
    "print('Успешно!\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8581f4064e406a6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "3# Преобразование отзывов в вектора\n",
    "В предложенном фрагменте кода мы используем модель fasttext(а именно \"cc.ru.300.bin\") для преобразования отзывов в вектора, которые как раз машина сможет обрабатывать\n",
    "\n",
    "def get_vector - функция для получения вектора из предложения(текста)\n",
    "def to_vector - функция для преобразования списка отзывов в вектора с разделением на положительные и отрицательные(использует def get_vector)\n",
    "def save_vector - сохраняет полученные вектора в json-файл"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6be17d9491b6345"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(\"Загрузка модели...\")\n",
    "import fasttext.util\n",
    "ft = fasttext.load_model('cc.ru.300.bin')\n",
    "\n",
    "\n",
    "def get_vector(review):\n",
    "    sentence = \"\".join(s + \" \" for s in review)\n",
    "    sentence_vector = ft.get_sentence_vector(sentence)\n",
    "    return sentence_vector\n",
    "\n",
    "def to_vector(lower_reviews_a):\n",
    "    print(\"Перевод отзывов в вектора...\")\n",
    "    reviews_v = {\"good\": [], \"bad\": []}\n",
    "    for i in range(len(json.loads(open('reviews.json').read())[\"good\"])):\n",
    "        reviews_v[\"good\"].append(get_vector(lower_reviews_a[i]).tolist())\n",
    "    for i in range(len(json.loads(open('reviews.json').read())[\"bad\"])):\n",
    "        reviews_v[\"bad\"].append(get_vector(lower_reviews_a[i + len(json.loads(open('reviews.json').read())[\"good\"])]).tolist())\n",
    "    return reviews_v\n",
    "    \n",
    "\n",
    "def save_vector(reviews_v):\n",
    "    print(\"Сохранение векторов...\")\n",
    "    with open('vectorized_reviews.json', 'w') as f:\n",
    "        json.dump(reviews_v, f)\n",
    "\n",
    "with open(\"lower_reviews.json\", \"r\", encoding='utf-8') as read_file:\n",
    "    reviews_lower = json.loads(read_file.read())\n",
    "reviews_vector = to_vector(reviews_lower[\"reviews\"])\n",
    "save_vector(reviews_vector)\n",
    "print('Успешно!\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ee6ec1bdc53b35b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "4# Суммаризация отзывов \n",
    "Здесь происходит удаление похожих на себя по содержанию отзывов. Мы используем библеотеку scipy.spatial для создания KD-дерева(дерево векторов). Используя наше дерево мы находим несколько наиболее схожих векторов на другие вектора, удаляя их и оставляя наиболее похожий(ближний). А в конце вывод полученных результатов"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e3e9ee106372639"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "with open(\"vectorized_reviews.json\", \"r\") as read_file:\n",
    "    load_data = json.load(read_file)\n",
    "\n",
    "vec_reviews_good = np.array(load_data[\"good\"])\n",
    "vec_reviews_bad = np.array(load_data[\"bad\"])\n",
    "print(\"Ищу общие схожести в отзывах...\")\n",
    "reviews = json.loads(open('reviews.json').read())\n",
    "reviews_final = {\"good\": [], \"bad\": []}\n",
    "for vec in vec_reviews_good:\n",
    "    try:\n",
    "        tree = spatial.KDTree(vec_reviews_good)\n",
    "        similar_review = tree.query(vec, max(5, int(round(len(json.loads(open('reviews.json').read())[\"good\"]) * 0.5) ** 0.5)))\n",
    "        similar_vec = [vec_reviews_good[i].tolist() for i in similar_review[1]]\n",
    "        for s in similar_vec:\n",
    "            ind = load_data[\"good\"].index(s)\n",
    "    \n",
    "            reviews[\"good\"].pop(ind)\n",
    "            r = reviews[\"good\"][ind]\n",
    "        reviews_final[\"good\"].append(r)\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "r = None\n",
    "for vec in vec_reviews_bad:\n",
    "    try:\n",
    "        tree = spatial.KDTree(vec_reviews_bad)\n",
    "        similar_review = tree.query(vec, max(5, int(round(len(json.loads(open('reviews.json').read())[\"bad\"]) * 0.5) ** 0.5)))\n",
    "        similar_vec = [vec_reviews_bad[i].tolist() for i in similar_review[1]]\n",
    "        for s in similar_vec:\n",
    "            ind = load_data[\"bad\"].index(s)\n",
    "    \n",
    "            reviews[\"bad\"].pop(ind)\n",
    "            r = reviews[\"bad\"][ind]\n",
    "        reviews_final[\"bad\"].append(r)\n",
    "    except:\n",
    "        continue\n",
    "print(\"\\nПОЛОЖИТЕЛЬНЫЕ ЧЕРТЫ:\\n\")\n",
    "print(\"\\n\\n\".join(reviews_final[\"good\"]))\n",
    "print(len(reviews_final[\"good\"]), len(json.loads(open('reviews.json').read())[\"good\"]))\n",
    "print(\"\\nНЕГАТИВНЫЕ ЧЕРТЫ:\\n\")\n",
    "print(\"\\n\\n\".join(reviews_final[\"bad\"]))\n",
    "print(len(reviews_final[\"bad\"]))\n",
    "print(len(reviews_final[\"good\"] + reviews_final[\"bad\"]), len(json.loads(open('reviews.json').read())[\"good\"] + json.loads(open('reviews.json').read())[\"bad\"]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88096d36ff196e2d",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
